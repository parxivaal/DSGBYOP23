{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48116742",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Required Libraries'''\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sympy\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(int(np.random.rand(1)[0]*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87323994",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Helper Functions'''\n",
    "\n",
    "def ground_state(H):\n",
    "    ''' H : matrix form of Hamiltonian (array)\n",
    "        outputs: [ground state, ground state energy] of H'''\n",
    "    H = scipy.sparse.csr_matrix(np.array(H))\n",
    "    eigvals, eigvecs = scipy.sparse.linalg.eigs(H)\n",
    "    return eigvecs[:, np.argmin(eigvals)], np.real(min(eigvals))\n",
    "\n",
    "def operator(pauli):\n",
    "    ''' pauli : (string) eg. XXZ \n",
    "        outputs: matrix form of the pauli term'''\n",
    "    ops = {'I':np.array([[1,0],[0,1]]),\n",
    "           'X':np.array([[0,1],[1,0]]),\n",
    "           'Y':np.array([[0,-1j],[1j,0]]),\n",
    "           'Z':np.array([[1,0],[0,-1]])}\n",
    "    term = ops[pauli[0]]\n",
    "    for i in range(1,len(pauli)):\n",
    "        term = np.kron(term,ops[pauli[i]])\n",
    "    return term\n",
    "\n",
    "def expectation(O,psi):\n",
    "    '''O    : observable's matrix (array)\n",
    "       psi  : Statevector (array)\n",
    "       outputs : expectation value'''\n",
    "    return np.matmul(psi,np.matmul(O,psi.conj().T)).round(5)\n",
    "\n",
    "def partial_trace(rho, keep, dims):\n",
    "    '''rho : the density matrix of the system\n",
    "       keep : the subsystems you want to trace out\n",
    "       dims : dimensions of the all the subsystems\n",
    "       outputs : partial trace'''\n",
    "    keep = np.array(keep)\n",
    "    dims = np.array(dims)\n",
    "    n = len(dims)\n",
    "    N = np.prod(dims[keep])\n",
    "\n",
    "    index1 = [i for i in range(n)]\n",
    "    index2 = [n+i if i in keep else i for i in range(n)]\n",
    "    rho = rho.reshape(np.tile(dims,2))\n",
    "    rho = np.einsum(rho, index1+index2)\n",
    "    return rho.reshape(N, N)\n",
    "\n",
    "def entanglement_entropy(sv,n):\n",
    "    '''sv : statevector of the 1d system\n",
    "       n : index of the edge where we are considering the partition\n",
    "       outputs: the entanglement entropy of the system on the left'''\n",
    "    rho = np.outer(sv.conj().T, sv)\n",
    "    dims = np.log2(len(sv))\n",
    "    ndim = [2 for i in range(int(dims))]\n",
    "    rho = partial_trace(rho, n, ndim)\n",
    "    return np.real((-1)*(np.trace(rho @ scipy.linalg.logm(rho))))\n",
    "\n",
    "def renyi_trace(rho,n):\n",
    "    '''sv : statevector of the 2d system\n",
    "       n : index of the subsystem whose entropy we aim to calculate\n",
    "       outputs: partial trace'''\n",
    "    dims = int(np.log2(len(rho)))\n",
    "    ndim = [2 for i in range(dims)]\n",
    "    rho = partial_trace(rho,n,ndim)\n",
    "    return rho\n",
    "\n",
    "def renyi_entropy_mat(rho):\n",
    "    '''sv : statevector of the 2d system\n",
    "       outputs: the renyi entropy matrix'''\n",
    "    n = int(np.log2(len(rho)))\n",
    "    entropi = np.zeros((n,n), dtype=float)\n",
    "    for i in range(n):\n",
    "        ent = renyi_trace(rho,i)\n",
    "        entropi[i,i] = -np.log(np.real(np.trace(np.matmul(ent,ent))))\n",
    "        for j in range(i+1,n):\n",
    "            ent = renyi_trace(rho,[i,j])\n",
    "            entropi[i,j] = entropi[j,i] = -np.log(np.real(np.trace(np.matmul(ent,ent))))\n",
    "    return entropi\n",
    "\n",
    "def graph_data(J):\n",
    "    '''J : coupling matrix for 2d systems\n",
    "       outputs : data preprocessed for GCN'''\n",
    "    cmax = np.max(J, axis=(0,1)).reshape((1,1))\n",
    "    cmin = np.min(J, axis=(0,1)).reshape((1,1))\n",
    "    J = (J - cmin) / (cmax - cmin)\n",
    "    wts = []\n",
    "    edges = [[],[]]\n",
    "    for i in range(len(J)):\n",
    "        for j in range(i):\n",
    "            if adj_mat[j][i]!=0:\n",
    "                edges[0].append(j)\n",
    "                edges[0].append(i)\n",
    "                edges[1].append(i)\n",
    "                edges[1].append(j)\n",
    "                wts.append(J[j][i])\n",
    "                wts.append(J[j][i])\n",
    "    wts = torch.tensor(wts).float()\n",
    "    edges = torch.tensor(edges).float()\n",
    "    return GraphData(x=torch.eye(len(J)).float(),edge_index=edges,edge_weights=wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66070f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Saving and Loading data'''\n",
    "import pickle\n",
    "def dump(name,var):\n",
    "    with open(name+'.pkl', 'wb') as file:\n",
    "        pickle.dump(var, file)\n",
    "\n",
    "def load(name):\n",
    "    with open(name+'.pkl', 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e6cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Classical Shadow Functions'''\n",
    "# outputs a list of snapshot states\n",
    "def classical_shadow(circuit,params,num_shadows,num_qubits):\n",
    "    '''circuit     : Any Quantum Circuit containing the State\n",
    "       params      : List of Parameters needed in the Quantum Circuit\n",
    "       num_shadows : Number of snapshots to be extracted\n",
    "       num_qubits  : Number of qubits used in the Circuit\n",
    "       outputs : classical shadows, measurement indexes'''\n",
    "    unitary = {0:qml.PauliX, 1:qml.PauliY, 2:qml.PauliZ}\n",
    "    mat = np.random.randint(0,3,size=(num_shadows,num_qubits))\n",
    "    exp = []\n",
    "    for i in range(num_shadows):\n",
    "        k = []\n",
    "        for j in range(num_qubits):\n",
    "            k.append(unitary[int(mat[i,j])](int(j)))\n",
    "        exp.append(circuit(params,k).numpy())\n",
    "    \n",
    "    def snapshot_state(string,index):\n",
    "            unitary = {0 : {-1 : (1/np.sqrt(2))*np.array([[1],[-1]]), 1 : (1/np.sqrt(2))*np.array([[1],[1]])},\n",
    "                       1 : {-1 : (1/np.sqrt(2))*np.array([[1],[-1j]]), 1 : (1/np.sqrt(2))*np.array([[1],[1j]])},\n",
    "                       2 : {-1 : np.array([[0],[1]]), 1 : np.array([[1],[0]])}}\n",
    "            eye = np.array([[1,0],[0,1]])\n",
    "            state = []\n",
    "            for i in range(len(string)):\n",
    "                term = unitary[index[i]][string[i]]\n",
    "                state.append(3*np.matmul(term,term.conj().T) - eye)\n",
    "    \n",
    "            ans = state[0]\n",
    "            for j in range(1,len(string)):\n",
    "                ans = np.kron(ans,state[j])\n",
    "            return ans\n",
    "    \n",
    "    snaps = []\n",
    "    for i in range(num_shadows):\n",
    "        snaps.append(snapshot_state(exp[i],mat[i]))\n",
    "        \n",
    "    exp = np.array(exp)\n",
    "    exp[exp==-1] = 0\n",
    "    values = 2*mat + exp\n",
    "    return snaps, values\n",
    "\n",
    "# reconstructs a state density matrix of input shadow(list of snapshots) \n",
    "def reconstructed_state(shadow):\n",
    "    '''shadow : List of classical shadows of the state to be reconstructed\n",
    "       outputs : the reconstructed state'''\n",
    "    num_snapshots = len(shadow)\n",
    "    num_qubits = int(np.log2(len(shadow[0])))\n",
    "    state = np.zeros((2**num_qubits, 2**num_qubits),dtype=complex)\n",
    "    for i in range(num_snapshots):\n",
    "        state += shadow[i]\n",
    "    return state/num_snapshots\n",
    "\n",
    "# provides an approximate observable expectation value\n",
    "def obs_prediction(obs,shadow,K):\n",
    "    '''obs    : Observable to be predicted (Matrix form)\n",
    "       shadow : List of shadows\n",
    "       K      : number of partitions\n",
    "       outputs : the predicted observable expectation value'''\n",
    "    N = len(shadow)\n",
    "    qubits = int(np.log2(len(shadow[0])))\n",
    "    num = int(np.floor(N/K))\n",
    "    \n",
    "    k = 0\n",
    "    rho = []\n",
    "    for i in range(K):\n",
    "        term = np.zeros((2**qubits,2**qubits),dtype=complex)\n",
    "        for j in range(num):\n",
    "            term += shadow[k]\n",
    "            k+=1\n",
    "        rho.append((1/num)*term)\n",
    "        \n",
    "    exp = []\n",
    "    for i in rho:\n",
    "        exp.append(np.trace(np.matmul(obs,i)))\n",
    "    return np.real(np.median(exp))\n",
    "\n",
    "# classical shadow(snapshots) of ground state of input Hamiltonian\n",
    "def groundstate_shadow(num_snaps,H):\n",
    "    '''num_snaps : number of snapshots (more snapshots -> high computational cost along with high accuracy)\n",
    "       H : Matrix form of Hamiltonian (array)'''\n",
    "    state,v = ground_state(H)\n",
    "    num_qubits = int(np.log2(len(H)))\n",
    "    \n",
    "    dev = qml.device(\"default.qubit\", wires=num_qubits,shots=1)\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(state,obs):\n",
    "        state = state/np.linalg.norm(state)\n",
    "        qml.QubitStateVector(state, wires=range(num_qubits))\n",
    "        return [qml.expval(o) for o in obs]\n",
    "    \n",
    "    shadow, values = classical_shadow(circuit,state,num_snaps,num_qubits)\n",
    "    return shadow, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febb1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The Heisenberg Spin Model'''\n",
    "def Heisenberg_Model(J):\n",
    "    ''' outputs the matrix corresponding to the Hamiltonian of the Heisenberg spin model with input coupling matrix J'''\n",
    "    N = len(J)\n",
    "    edges = []\n",
    "    for i in range(N):\n",
    "        for j in range(i):\n",
    "            edges.append([j,i])\n",
    "    \n",
    "    iden = 'I'\n",
    "    for i in range(N-2):\n",
    "        iden+='I'\n",
    "    \n",
    "    H_terms = []\n",
    "    H = np.zeros((2**N,2**N),dtype=complex)\n",
    "    for term in edges:\n",
    "        for m in ['X','Y','Z']:\n",
    "            K = iden[:term[0]]+m+iden[term[0]+1:term[1]]+m+iden[term[1]:]\n",
    "            H = H + J[term[0]][term[1]]*operator(K)\n",
    "    return H\n",
    "\n",
    "def random_couplings(row,col):\n",
    "    '''outputs a random coupling matrix corresponding to input model configuration'''\n",
    "    edges = []\n",
    "    k = np.array([[i+j*col for i in range(col)] for j in range(row)])\n",
    "    for j in range(row):\n",
    "        for i in range(col-1):\n",
    "            edges.append((k[j][i],k[j][i+1]))\n",
    "\n",
    "    for j in range(col):\n",
    "        for i in range(row-1):\n",
    "            edges.append((k[i][j],k[i+1][j]))\n",
    "\n",
    "    coeffs = []\n",
    "    mat = np.zeros((row*col,row*col))\n",
    "    for i,j in edges:\n",
    "        k = np.random.rand(1)[0]*2\n",
    "        mat[i,j] = k\n",
    "        mat[j,i] = k\n",
    "        coeffs.append(k)\n",
    "    return mat, coeffs\n",
    "\n",
    "def given_couplings(row,col,coeffs):\n",
    "    '''forms the coupling matrix for the provided coefficients'''\n",
    "    edges = []\n",
    "    k = np.array([[i+j*col for i in range(col)] for j in range(row)])\n",
    "    for j in range(row):\n",
    "        for i in range(col-1):\n",
    "            edges.append((k[j][i],k[j][i+1]))\n",
    "\n",
    "    for j in range(col):\n",
    "        for i in range(row-1):\n",
    "            edges.append((k[i][j],k[i+1][j]))\n",
    "    \n",
    "    m = 0\n",
    "    mat = np.zeros((row*col,row*col))\n",
    "    for i,j in edges:\n",
    "        k = coeffs[m]\n",
    "        m+=1\n",
    "        mat[i,j] = k\n",
    "        mat[j,i] = k \n",
    "    return mat\n",
    "\n",
    "def correlationfn(i,j,N):\n",
    "        C=np.zeros((2**N,2**N),dtype=complex)\n",
    "        term = ['I','I','I']\n",
    "        for k in range(N):\n",
    "            if (i==k+1 or j==k+1) and i!=j: \n",
    "                term[0]+='X'\n",
    "                term[1]+='Y'\n",
    "                term[2]+='Z'\n",
    "            else: \n",
    "                term[0]+='I'\n",
    "                term[1]+='I'\n",
    "                term[2]+='I'\n",
    "        term = [term[0][1:],term[1][1:],term[2][1:]]\n",
    "        for i in term: C += operator(i)\n",
    "        return (1/3)*C\n",
    "\n",
    "def corr_mat(H):\n",
    "    ''' this function gives the correlation matrix calculated on the ground statevector obtained using Exact Diagonalization'''\n",
    "    num_qubits = int(np.log2(len(H)))\n",
    "    matrix = np.zeros((num_qubits,num_qubits), dtype=complex)\n",
    "    state,value = ground_state(H)\n",
    "    for i in range(num_qubits):\n",
    "        for j in range(num_qubits):\n",
    "            op = correlationfn(i+1,j+1,num_qubits)\n",
    "            matrix[i,j] = expectation(op,state)\n",
    "    return np.real(matrix)\n",
    "\n",
    "def shadow_corr(num_shots,H):\n",
    "    '''The approximate correlation matrix constructed using the prediction algortihm of classical shadows'''\n",
    "    num_qubits = int(np.log2(len(H)))\n",
    "    matrix = np.zeros((num_qubits,num_qubits), dtype=complex)\n",
    "    shad, values = groundstate_shadow(num_shots,H)\n",
    "\n",
    "    for i in range(num_qubits):\n",
    "        for j in range(num_qubits):\n",
    "            op = correlationfn(i+1,j+1,num_qubits)\n",
    "            matrix[i,j] = obs_prediction(op,shad,5)\n",
    "    return np.real(matrix), shad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9300ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coupling Matrix:\n",
      " [[0.   1.3  1.76 0.  ]\n",
      " [1.3  0.   0.   0.36]\n",
      " [1.76 0.   0.   1.01]\n",
      " [0.   0.36 1.01 0.  ]]\n",
      "\n",
      "Ground State Energy: -8.87737611573505\n",
      "\n",
      "Renyi Entropy Matrix:\n",
      " [[0.69 0.47 0.61 1.1 ]\n",
      " [0.47 0.69 1.1  0.61]\n",
      " [0.61 1.1  0.69 0.47]\n",
      " [1.1  0.61 0.47 0.69]]\n",
      "\n",
      "The correlation matrix obtained from exact ground state\n",
      " [[ 1.   -0.71 -0.62  0.33]\n",
      " [-0.71  1.    0.33 -0.62]\n",
      " [-0.62  0.33  1.   -0.71]\n",
      " [ 0.33 -0.62 -0.71  1.  ]]\n",
      "\n",
      "The correlation matrix directly predicted by classical shadows\n",
      " [[ 1.   -0.72 -0.67  0.33]\n",
      " [-0.72  1.    0.39 -0.61]\n",
      " [-0.67  0.39  1.   -0.72]\n",
      " [ 0.33 -0.61 -0.72  1.  ]]\n",
      "\n",
      "Shadow Prediction of GSE: -8.182674002394394\n",
      "\n",
      "Shadow Computation of GSE: -8.415405902907063\n"
     ]
    }
   ],
   "source": [
    "num_snaps = 1000\n",
    "coupling, coeffs  = random_couplings(2,2)\n",
    "print('Coupling Matrix:\\n', coupling.round(2))\n",
    "\n",
    "H = Heisenberg_Model(coupling)\n",
    "g_state, g_energy = ground_state(H)\n",
    "print('\\nGround State Energy:',g_energy)\n",
    "\n",
    "rho = np.outer(g_state, g_state.conj().T)\n",
    "entropy = renyi_entropy_mat(rho)\n",
    "print('\\nRenyi Entropy Matrix:\\n', entropy.round(2))\n",
    "\n",
    "correlations = np.real(corr_mat(H))\n",
    "print('\\nThe correlation matrix obtained from exact ground state\\n',correlations.round(2))\n",
    "\n",
    "shadow_correlations, shadow = shadow_corr(num_snaps,H)\n",
    "print('\\nThe correlation matrix directly predicted by classical shadows\\n', shadow_correlations.round(2))\n",
    "\n",
    "g_shadow, g_values = groundstate_shadow(num_snaps,H)\n",
    "shadow_predicted_energy = obs_prediction(H,g_shadow,5)\n",
    "reconstructed = reconstructed_state(g_shadow)\n",
    "shadow_energy = np.real(np.trace(np.matmul(H,reconstructed)))\n",
    "print('\\nShadow Prediction of GSE:',shadow_predicted_energy)\n",
    "print('\\nShadow Computation of GSE:',shadow_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5c9cfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2040710bc40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Visual Plots for Comparison'''\n",
    "f, axarr = plt.subplots(1,3)\n",
    "\n",
    "axarr[0].set_title('Exact')\n",
    "axarr[0].imshow(correlations, cmap=plt.get_cmap(\"RdBu\"), vmin = -1,vmax = 1)\n",
    "\n",
    "axarr[1].set_title('Classical Shadow')\n",
    "axarr[1].imshow(shadow_correlations, cmap=plt.get_cmap(\"RdBu\"), vmin = -1,vmax = 1)\n",
    "\n",
    "axarr[2].set_title('Difference')\n",
    "axarr[2].imshow(correlations-shadow_correlations, cmap=plt.get_cmap(\"RdBu\"), vmin = -1,vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f3c5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(num_data, model_shape, num_snaps):\n",
    "    \n",
    "    params, shadows, states, measurements = [], [], [], []\n",
    "    \n",
    "    for i in range(num_data):\n",
    "        J, terms = random_couplings(model_shape[0], model_shape[1])\n",
    "        H = Heisenberg_Model(J)\n",
    "        gshadow, val = groundstate_shadow(num_snaps,H)\n",
    "        state = reconstructed_state(gshadow)\n",
    "        shadows.append(gshadow)\n",
    "        measurements.append(val)\n",
    "        params.append(terms)\n",
    "        states.append(state)\n",
    "        \n",
    "    return np.array(params), np.array(shadows), np.array(states), np.array(measurements)\n",
    "\n",
    "params, shadows, states, measurements  = generate_dataset(num_data=100, model_shape=(2,2), num_snaps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e395d500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(measurements[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55dce0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encoding once in log space\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        return x\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    attention_weights = nn.functional.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        attention_weights = dropout(attention_weights)\n",
    "\n",
    "    context = torch.matmul(attention_weights, value)\n",
    "    return context, attention_weights\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, d_model, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.linear_q = nn.Linear(d_model, d_model)\n",
    "        self.linear_k = nn.Linear(d_model, d_model)\n",
    "        self.linear_v = nn.Linear(d_model, d_model)\n",
    "        self.linear_o = nn.Linear(d_model, d_model)\n",
    "        self.attn = None\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "\n",
    "        n_batches = query.size(0)\n",
    "        query, key, value = [\n",
    "            lin(x).view(n_batches, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        x = x.transpose(1, 2).contiguous().view(n_batches, -1, self.n_heads * self.d_k)\n",
    "\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)\n",
    "    \n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True, unbiased=False)\n",
    "        return ((x - mean) / (std + self.eps)) * self.gamma + self.beta\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    \n",
    "import torch.nn as nn\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn: MultiHeadAttention, feed_forward: PositionWiseFeedForward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer1 = SublayerConnection(size, dropout)\n",
    "        self.sublayer2 = SublayerConnection(size, dropout)\n",
    "        self.sublayer3 = SublayerConnection(size, dropout)\n",
    "\n",
    "    def forward(self, x, tgt_mask):\n",
    "        x = self.sublayer1(x, lambda x: self.self_attn(\n",
    "            query=x, key=x, value=x, mask=tgt_mask\n",
    "        ))\n",
    "        x = self.sublayer2(x, lambda x: self.self_attn(\n",
    "            query=x, key=x, value=x, mask=tgt_mask\n",
    "        ))\n",
    "        return self.sublayer3(x, self.feed_forward)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer: DecoderLayer, n_layers: int):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(len(n_layers)):\n",
    "            self.layers.append(layer)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, tgt_mask=mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2edb6a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7308\\707821551.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKLDLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.98\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCosineAnnealingLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transformer' is not defined"
     ]
    }
   ],
   "source": [
    "class KLDLoss(nn.Module):\n",
    "    def __init__(self, padding):\n",
    "        super(KLDLoss, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction='sum')\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        onehot = torch.zeros_like(x)\n",
    "        onehot.scatter_(1, target.unsqueeze(1), 1.0)\n",
    "        if self.padding >= 0:\n",
    "            onehot[:, self.padding] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding)\n",
    "        if mask.dim() > 0:\n",
    "            onehot.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        loss = self.criterion(x, target_onehot)\n",
    "        return loss\n",
    "\n",
    "criterion = KLDLoss(padding=-1)\n",
    "steps = 2000\n",
    "optimizer = torch.optim.AdamW(transformer.parameters(), lr=1e-3, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=steps, eta_min=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TgtBatch:\n",
    "    def __init__(self, tgt, pad):\n",
    "        self.tgt = tgt[:, :-1]\n",
    "        self.tgt_y = tgt[:, 1:]\n",
    "        self.tgt_mask = make_std_mask(self.tgt, pad)\n",
    "        self.ntokens = (self.tgt_y != pad).data.sum()\n",
    "        \n",
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
    "    return mask == 0\n",
    "\n",
    "\n",
    "def make_std_mask(tgt, pad):\n",
    "    tgt_mask = (tgt != pad).unsqueeze(-2) \n",
    "    tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n",
    "    return tgt_mask\n",
    "\n",
    "\n",
    "def batch_iterator(data, graphs_list, iterations, batch_size, shuffle=True):\n",
    "    for step in range(1, iterations + 1):\n",
    "        indices = rng.choice(len(data), batch_size, replace=True)\n",
    "        tgt_batch = TgtBatch(data[indices], pad=-1)\n",
    "        graphs_batch = GraphBatch.from_data_list(data_list=[graphs_list[i] for i in indices])\n",
    "        yield tgt_batch, graphs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb74985",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, embed, generator, num_outcomes, dim_model, pad_token, start_token, end_token, tokenshift):\n",
    "        super(GraphTransformer, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        self.n_outcomes = n_outcomes\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.pad_token = pad_token\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.token_shift = token_shift\n",
    "\n",
    "    def forward(self, tgt, tgt_mask, coupling_graph):\n",
    "        \"\"\" process masked target sequences \"\"\"\n",
    "        tgt_embed = self.tgt_embed(tgt)\n",
    "        graph_embed = self.encoder(coupling_graph)\n",
    "        graph_embed = graph_embed[:, :tgt_embed.shape[1], :]\n",
    "        tgt_embed = tgt_embed + graph_embed\n",
    "\n",
    "        return graph_embed, self.decoder(tgt_embed, tgt_mask)\n",
    "\n",
    "    def sample_batch(self, batch_size, coupling_graph, qubits):\n",
    "        num_valid_samples = 0\n",
    "        valid_samples = None\n",
    "\n",
    "        num_restarts = 0\n",
    "\n",
    "        while num_valid_samples < batch_size:\n",
    "            tgt = torch.ones(batch_size - num_valid_samples, 1).type(\n",
    "                LongTensor) * self.start_token\n",
    "\n",
    "            for i in range(qubits):\n",
    "                mask = make_std_mask(tgt, pad=self.pad_token)\n",
    "\n",
    "                _, out = self.forward(tgt, mask, coupling_graph)\n",
    "                log_probs = self.generator(out[:, -1])\n",
    "                probs = torch.exp(log_probs).detach()\n",
    "                probs = probs / probs.sum(axis=-1).reshape(\n",
    "                    batch_size - num_valid_samples, 1)\n",
    "\n",
    "                next_outcomes = torch.multinomial(probs, 1, replacement=True)\n",
    "\n",
    "                tgt = torch.cat([tgt, next_outcomes], dim=1)\n",
    "            tgt = tgt.cpu().numpy()\n",
    "            tgt = tgt[:, 1:] - self.token_shift\n",
    "            tgt = tgt[np.all(tgt >= 0, axis=1), :]\n",
    "\n",
    "            if valid_samples is None:\n",
    "                valid_samples = tgt\n",
    "            else:\n",
    "                valid_samples = np.concatenate([valid_samples, tgt], axis=0)\n",
    "\n",
    "            num_valid_samples = valid_samples.shape[0]\n",
    "\n",
    "            num_restarts += 1\n",
    "            if num_restarts > 10:\n",
    "                print(\n",
    "                    f'sampling timed out: got {num_valid_samples} instead of {batch_size}')\n",
    "                break\n",
    "\n",
    "        return valid_samples\n",
    "\n",
    "    def sample(self, samples, coupling_graph, qubits, batch_size=1000,\n",
    "               print_progress=True) -> np.ndarray:\n",
    "        batch_sizes = [batch_size] * int(samples // batch_size)\n",
    "        batch_sizes = batch_sizes + (\n",
    "            [] if samples % batch_size == 0 else [samples % batch_size])\n",
    "\n",
    "        if print_progress:\n",
    "            pbar = tqdm(batch_sizes,\n",
    "                        postfix=f'generating {samples} samples from model...')\n",
    "        else:\n",
    "            pbar = batch_sizes\n",
    "\n",
    "        batch_samples = [self.sample_batch(bs, coupling_graph, qubits) for bs in pbar]\n",
    "        samples = np.concatenate(batch_samples, axis=0)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34df025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, num_qubits, input_dim, gcn_dim, transformer_dim, num_layers):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        channel = [input_dim]\n",
    "        channel = channel + [2 ** (num_layers - 1 - i) * gcn_dim for i in range(num_layers - 1)]\n",
    "        channel = channel + [gcn_dim]\n",
    "        \n",
    "        self.transformer = transformer_dim\n",
    "        self.channels = gcn_dim\n",
    "        self.nodes = num_qubits\n",
    "        \n",
    "        self.gcn = []\n",
    "        for i in range(len(channel)-1):\n",
    "            self.gcn.append(GCNConv(channel[i],channel[i+1]))\n",
    "        \n",
    "        self.linear = nn.Linear(num_qubits*gcn_dim, transformer_dim)\n",
    "        self.layers = nn.Sequential(*self.gcn, self.linear)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, index, weight = data.x, data.edge_index, data.edge_weight\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x, index, weight).relu()\n",
    "\n",
    "        embed = x.view(-1, self.channels * self.nodes)\n",
    "        proj = self.layers[-1](embed)\n",
    "        proj = proj.view(data.num_graphs, -1, self.transformer)\n",
    "        return proj\n",
    "\n",
    "num_qubits = len(coupling)\n",
    "input_dim = len(measurements[0][0])\n",
    "gcn_dim = 16\n",
    "transformer_dim = 128\n",
    "num_layers = 3\n",
    "encoder = GCNEncoder(num_qubits, input_dim, gcn_dim, transformer_dim, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1138995",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4\n",
    "num_layers = 4\n",
    "dim_model = 128\n",
    "dim_ff = 4*128\n",
    "num_outcomes = 6\n",
    "dropout = 0.0\n",
    "pad_token = -1\n",
    "start_token = 0\n",
    "end_token = -1\n",
    "token_shift = 1\n",
    "\n",
    "attention = MultiHeadAttention(num_heads, dim_model, dropout)\n",
    "feedforward = PositionwiseFeedForward(dim_model, dim_ff, dropout)\n",
    "position = PositionalEncoding(dim_model, dropout)\n",
    "size = num_outcomes + token_shift\n",
    "\n",
    "generator = Generator(dim_model, size)\n",
    "decoder = Decoder(DecoderLayer(dim_model, deepcopy(attention), deepcopy(feedforward), dropout), n_layers = num_layers)\n",
    "embed = nn.Sequential(Embedding(dim_model, size), deepcopy(position))\n",
    "\n",
    "model = GraphTransformer(encoder=encoder, \n",
    "                         pad_token = pad_token, \n",
    "                         start_token = start_token, \n",
    "                         end_token = end_token,\n",
    "                         token_shift = token_shift, \n",
    "                         dim_model=dim_model, \n",
    "                         num_outcomes = num_outcomes,\n",
    "                         generator = generator,\n",
    "                         decoder = Decoder(DecoderLayer(dim_model, deepcopy(attention), deepcopy(feedforward), dropout), n_layers = num_layers),\n",
    "                         embed = nn.Sequential(Embedding(dim_model, size), deepcopy(position)))\n",
    "\n",
    "for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f76fae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
