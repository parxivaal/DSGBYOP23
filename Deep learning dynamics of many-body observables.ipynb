{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48116742",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Required Libraries'''\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sympy\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data as GraphData\n",
    "from torch_geometric.data import Batch as GraphBatch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(int(np.random.rand(1)[0]*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87323994",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Helper Functions'''\n",
    "\n",
    "def ground_state(H):\n",
    "    ''' H : matrix form of Hamiltonian (array)\n",
    "        outputs: [ground state, ground state energy] of H'''\n",
    "    H = scipy.sparse.csr_matrix(np.array(H))\n",
    "    eigvals, eigvecs = scipy.sparse.linalg.eigs(H)\n",
    "    return eigvecs[:, np.argmin(eigvals)], np.real(min(eigvals))\n",
    "\n",
    "def operator(pauli):\n",
    "    ''' pauli : (string) eg. XXZ \n",
    "        outputs: matrix form of the pauli term'''\n",
    "    ops = {'I':np.array([[1,0],[0,1]]),\n",
    "           'X':np.array([[0,1],[1,0]]),\n",
    "           'Y':np.array([[0,-1j],[1j,0]]),\n",
    "           'Z':np.array([[1,0],[0,-1]])}\n",
    "    term = ops[pauli[0]]\n",
    "    for i in range(1,len(pauli)):\n",
    "        term = np.kron(term,ops[pauli[i]])\n",
    "    return term\n",
    "\n",
    "def expectation(O,psi):\n",
    "    '''O    : observable's matrix (array)\n",
    "       psi  : Statevector (array)\n",
    "       outputs : expectation value'''\n",
    "    return np.matmul(psi,np.matmul(O,psi.conj().T)).round(5)\n",
    "\n",
    "def partial_trace(rho, keep, dims):\n",
    "    '''rho : the density matrix of the system\n",
    "       keep : the subsystems you want to trace out\n",
    "       dims : dimensions of the all the subsystems\n",
    "       outputs : partial trace'''\n",
    "    keep = np.array(keep)\n",
    "    dims = np.array(dims)\n",
    "    n = len(dims)\n",
    "    N = np.prod(dims[keep])\n",
    "\n",
    "    index1 = [i for i in range(n)]\n",
    "    index2 = [n+i if i in keep else i for i in range(n)]\n",
    "    rho = rho.reshape(np.tile(dims,2))\n",
    "    rho = np.einsum(rho, index1+index2)\n",
    "    return rho.reshape(N, N)\n",
    "\n",
    "def entanglement_entropy(sv,n):\n",
    "    '''sv : statevector of the 1d system\n",
    "       n : index of the edge where we are considering the partition\n",
    "       outputs: the entanglement entropy of the system on the left'''\n",
    "    rho = np.outer(sv.conj().T, sv)\n",
    "    dims = np.log2(len(sv))\n",
    "    ndim = [2 for i in range(int(dims))]\n",
    "    rho = partial_trace(rho, n, ndim)\n",
    "    return np.real((-1)*(np.trace(rho @ scipy.linalg.logm(rho))))\n",
    "\n",
    "def renyi_trace(rho,n):\n",
    "    '''sv : statevector of the 2d system\n",
    "       n : index of the subsystem whose entropy we aim to calculate\n",
    "       outputs: partial trace'''\n",
    "    dims = int(np.log2(len(rho)))\n",
    "    ndim = [2 for i in range(dims)]\n",
    "    rho = partial_trace(rho,n,ndim)\n",
    "    return rho\n",
    "\n",
    "def renyi_entropy_mat(rho):\n",
    "    '''sv : statevector of the 2d system\n",
    "       outputs: the renyi entropy matrix'''\n",
    "    n = int(np.log2(len(rho)))\n",
    "    entropi = np.zeros((n,n), dtype=float)\n",
    "    for i in range(n):\n",
    "        ent = renyi_trace(rho,i)\n",
    "        entropi[i,i] = -np.log(np.real(np.trace(np.matmul(ent,ent))))\n",
    "        for j in range(i+1,n):\n",
    "            ent = renyi_trace(rho,[i,j])\n",
    "            entropi[i,j] = entropi[j,i] = -np.log(np.real(np.trace(np.matmul(ent,ent))))\n",
    "    return entropi\n",
    "\n",
    "def graph_data(J):\n",
    "    '''J : coupling matrix for 2d systems\n",
    "       outputs : data preprocessed for GCN'''\n",
    "    cmax = np.max(J, axis=(0,1)).reshape((1,1))\n",
    "    cmin = np.min(J, axis=(0,1)).reshape((1,1))\n",
    "    J = (J - cmin) / (cmax - cmin)\n",
    "    wts = []\n",
    "    edges = [[],[]]\n",
    "    for i in range(len(J)):\n",
    "        for j in range(i):\n",
    "            if J[j][i]!=0:\n",
    "                edges[0].append(j)\n",
    "                edges[0].append(i)\n",
    "                edges[1].append(i)\n",
    "                edges[1].append(j)\n",
    "                wts.append(J[j][i])\n",
    "                wts.append(J[j][i])\n",
    "    wts = torch.tensor(wts).float()\n",
    "    edges = torch.tensor(edges).float()\n",
    "    return GraphData(x=torch.eye(len(J)).float(),edge_index=edges,edge_weights=wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66070f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Saving and Loading data'''\n",
    "import pickle\n",
    "def dump(name,var):\n",
    "    with open(name+'.pkl', 'wb') as file:\n",
    "        pickle.dump(var, file)\n",
    "\n",
    "def load(name):\n",
    "    with open(name+'.pkl', 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e6cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Classical Shadow Functions'''\n",
    "# outputs a list of snapshot states\n",
    "def classical_shadow(circuit,params,num_shadows,num_qubits):\n",
    "    '''circuit     : Any Quantum Circuit containing the State\n",
    "       params      : List of Parameters needed in the Quantum Circuit\n",
    "       num_shadows : Number of snapshots to be extracted\n",
    "       num_qubits  : Number of qubits used in the Circuit\n",
    "       outputs : classical shadows, measurement indexes'''\n",
    "    unitary = {0:qml.PauliX, 1:qml.PauliY, 2:qml.PauliZ}\n",
    "    mat = np.random.randint(0,3,size=(num_shadows,num_qubits))\n",
    "    exp = []\n",
    "    for i in range(num_shadows):\n",
    "        k = []\n",
    "        for j in range(num_qubits):\n",
    "            k.append(unitary[int(mat[i,j])](int(j)))\n",
    "        exp.append(circuit(params,k).numpy())\n",
    "    \n",
    "    def snapshot_state(string,index):\n",
    "            unitary = {0 : {-1 : (1/np.sqrt(2))*np.array([[1],[-1]]), 1 : (1/np.sqrt(2))*np.array([[1],[1]])},\n",
    "                       1 : {-1 : (1/np.sqrt(2))*np.array([[1],[-1j]]), 1 : (1/np.sqrt(2))*np.array([[1],[1j]])},\n",
    "                       2 : {-1 : np.array([[0],[1]]), 1 : np.array([[1],[0]])}}\n",
    "            eye = np.array([[1,0],[0,1]])\n",
    "            state = []\n",
    "            for i in range(len(string)):\n",
    "                term = unitary[index[i]][string[i]]\n",
    "                state.append(3*np.matmul(term,term.conj().T) - eye)\n",
    "    \n",
    "            ans = state[0]\n",
    "            for j in range(1,len(string)):\n",
    "                ans = np.kron(ans,state[j])\n",
    "            return ans\n",
    "    \n",
    "    snaps = []\n",
    "    for i in range(num_shadows):\n",
    "        snaps.append(snapshot_state(exp[i],mat[i]))\n",
    "        \n",
    "    exp = np.array(exp)\n",
    "    exp[exp==-1] = 0\n",
    "    values = 2*mat + exp\n",
    "    return snaps, values\n",
    "\n",
    "# reconstructs a state density matrix of input shadow(list of snapshots) \n",
    "def reconstructed_state(shadow):\n",
    "    '''shadow : List of classical shadows of the state to be reconstructed\n",
    "       outputs : the reconstructed state'''\n",
    "    num_snapshots = len(shadow)\n",
    "    num_qubits = int(np.log2(len(shadow[0])))\n",
    "    state = np.zeros((2**num_qubits, 2**num_qubits),dtype=complex)\n",
    "    for i in range(num_snapshots):\n",
    "        state += shadow[i]\n",
    "    return state/num_snapshots\n",
    "\n",
    "# provides an approximate observable expectation value\n",
    "def obs_prediction(obs,shadow,K):\n",
    "    '''obs    : Observable to be predicted (Matrix form)\n",
    "       shadow : List of shadows\n",
    "       K      : number of partitions\n",
    "       outputs : the predicted observable expectation value'''\n",
    "    N = len(shadow)\n",
    "    qubits = int(np.log2(len(shadow[0])))\n",
    "    num = int(np.floor(N/K))\n",
    "    \n",
    "    k = 0\n",
    "    rho = []\n",
    "    for i in range(K):\n",
    "        term = np.zeros((2**qubits,2**qubits),dtype=complex)\n",
    "        for j in range(num):\n",
    "            term += shadow[k]\n",
    "            k+=1\n",
    "        rho.append((1/num)*term)\n",
    "        \n",
    "    exp = []\n",
    "    for i in rho:\n",
    "        exp.append(np.trace(np.matmul(obs,i)))\n",
    "    return np.real(np.median(exp))\n",
    "\n",
    "# classical shadow(snapshots) of ground state of input Hamiltonian\n",
    "def groundstate_shadow(num_snaps,H):\n",
    "    '''num_snaps : number of snapshots (more snapshots -> high computational cost along with high accuracy)\n",
    "       H : Matrix form of Hamiltonian (array)'''\n",
    "    state,v = ground_state(H)\n",
    "    num_qubits = int(np.log2(len(H)))\n",
    "    \n",
    "    dev = qml.device(\"default.qubit\", wires=num_qubits,shots=1)\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(state,obs):\n",
    "        state = state/np.linalg.norm(state)\n",
    "        qml.QubitStateVector(state, wires=range(num_qubits))\n",
    "        return [qml.expval(o) for o in obs]\n",
    "    \n",
    "    shadow, values = classical_shadow(circuit,state,num_snaps,num_qubits)\n",
    "    return shadow, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febb1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The Heisenberg Spin Model'''\n",
    "def Heisenberg_Model(J):\n",
    "    ''' outputs the matrix corresponding to the Hamiltonian of the Heisenberg spin model with input coupling matrix J'''\n",
    "    N = len(J)\n",
    "    edges = []\n",
    "    for i in range(N):\n",
    "        for j in range(i):\n",
    "            edges.append([j,i])\n",
    "    \n",
    "    iden = 'I'\n",
    "    for i in range(N-2):\n",
    "        iden+='I'\n",
    "    \n",
    "    H_terms = []\n",
    "    H = np.zeros((2**N,2**N),dtype=complex)\n",
    "    for term in edges:\n",
    "        for m in ['X','Y','Z']:\n",
    "            K = iden[:term[0]]+m+iden[term[0]+1:term[1]]+m+iden[term[1]:]\n",
    "            H = H + J[term[0]][term[1]]*operator(K)\n",
    "    return H\n",
    "\n",
    "def random_couplings(row,col):\n",
    "    '''outputs a random coupling matrix corresponding to input model configuration'''\n",
    "    edges = []\n",
    "    k = np.array([[i+j*col for i in range(col)] for j in range(row)])\n",
    "    for j in range(row):\n",
    "        for i in range(col-1):\n",
    "            edges.append((k[j][i],k[j][i+1]))\n",
    "\n",
    "    for j in range(col):\n",
    "        for i in range(row-1):\n",
    "            edges.append((k[i][j],k[i+1][j]))\n",
    "\n",
    "    coeffs = []\n",
    "    mat = np.zeros((row*col,row*col))\n",
    "    for i,j in edges:\n",
    "        k = np.random.rand(1)[0]*2\n",
    "        mat[i,j] = k\n",
    "        mat[j,i] = k\n",
    "        coeffs.append(k)\n",
    "    return mat, coeffs\n",
    "\n",
    "def given_couplings(row,col,coeffs):\n",
    "    '''forms the coupling matrix for the provided coefficients'''\n",
    "    edges = []\n",
    "    k = np.array([[i+j*col for i in range(col)] for j in range(row)])\n",
    "    for j in range(row):\n",
    "        for i in range(col-1):\n",
    "            edges.append((k[j][i],k[j][i+1]))\n",
    "\n",
    "    for j in range(col):\n",
    "        for i in range(row-1):\n",
    "            edges.append((k[i][j],k[i+1][j]))\n",
    "    \n",
    "    m = 0\n",
    "    mat = np.zeros((row*col,row*col))\n",
    "    for i,j in edges:\n",
    "        k = coeffs[m]\n",
    "        m+=1\n",
    "        mat[i,j] = k\n",
    "        mat[j,i] = k \n",
    "    return mat\n",
    "\n",
    "def correlationfn(i,j,N):\n",
    "        C=np.zeros((2**N,2**N),dtype=complex)\n",
    "        term = ['I','I','I']\n",
    "        for k in range(N):\n",
    "            if (i==k+1 or j==k+1) and i!=j: \n",
    "                term[0]+='X'\n",
    "                term[1]+='Y'\n",
    "                term[2]+='Z'\n",
    "            else: \n",
    "                term[0]+='I'\n",
    "                term[1]+='I'\n",
    "                term[2]+='I'\n",
    "        term = [term[0][1:],term[1][1:],term[2][1:]]\n",
    "        for i in term: C += operator(i)\n",
    "        return (1/3)*C\n",
    "\n",
    "def corr_mat(H):\n",
    "    ''' this function gives the correlation matrix calculated on the ground statevector obtained using Exact Diagonalization'''\n",
    "    num_qubits = int(np.log2(len(H)))\n",
    "    matrix = np.zeros((num_qubits,num_qubits), dtype=complex)\n",
    "    state,value = ground_state(H)\n",
    "    for i in range(num_qubits):\n",
    "        for j in range(num_qubits):\n",
    "            op = correlationfn(i+1,j+1,num_qubits)\n",
    "            matrix[i,j] = expectation(op,state)\n",
    "    return np.real(matrix)\n",
    "\n",
    "def shadow_corr(num_shots,H):\n",
    "    '''The approximate correlation matrix constructed using the prediction algortihm of classical shadows'''\n",
    "    num_qubits = int(np.log2(len(H)))\n",
    "    matrix = np.zeros((num_qubits,num_qubits), dtype=complex)\n",
    "    shad, values = groundstate_shadow(num_shots,H)\n",
    "\n",
    "    for i in range(num_qubits):\n",
    "        for j in range(num_qubits):\n",
    "            op = correlationfn(i+1,j+1,num_qubits)\n",
    "            matrix[i,j] = obs_prediction(op,shad,5)\n",
    "    return np.real(matrix), shad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9300ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coupling Matrix:\n",
      " [[0.   1.3  0.84 0.  ]\n",
      " [1.3  0.   0.   0.89]\n",
      " [0.84 0.   0.   0.69]\n",
      " [0.   0.89 0.69 0.  ]]\n",
      "\n",
      "Ground State Energy: -7.465351993282394\n",
      "\n",
      "Renyi Entropy Matrix:\n",
      " [[0.69 0.43 0.66 1.11]\n",
      " [0.43 0.69 1.11 0.66]\n",
      " [0.66 1.11 0.69 0.43]\n",
      " [1.11 0.66 0.43 0.69]]\n",
      "\n",
      "The correlation matrix obtained from exact ground state\n",
      " [[ 1.   -0.73 -0.6   0.33]\n",
      " [-0.73  1.    0.33 -0.6 ]\n",
      " [-0.6   0.33  1.   -0.73]\n",
      " [ 0.33 -0.6  -0.73  1.  ]]\n",
      "\n",
      "The correlation matrix directly predicted by classical shadows\n",
      " [[ 1.   -0.78 -0.52  0.27]\n",
      " [-0.78  1.    0.27 -0.63]\n",
      " [-0.52  0.27  1.   -0.69]\n",
      " [ 0.27 -0.63 -0.69  1.  ]]\n",
      "\n",
      "Shadow Prediction of GSE: -8.159863530607618\n",
      "\n",
      "Shadow Computation of GSE: -8.188365621758836\n"
     ]
    }
   ],
   "source": [
    "num_snaps = 1000\n",
    "coupling, coeffs  = random_couplings(2,2)\n",
    "print('Coupling Matrix:\\n', coupling.round(2))\n",
    "\n",
    "H = Heisenberg_Model(coupling)\n",
    "g_state, g_energy = ground_state(H)\n",
    "print('\\nGround State Energy:',g_energy)\n",
    "\n",
    "rho = np.outer(g_state, g_state.conj().T)\n",
    "entropy = renyi_entropy_mat(rho)\n",
    "print('\\nRenyi Entropy Matrix:\\n', entropy.round(2))\n",
    "\n",
    "correlations = np.real(corr_mat(H))\n",
    "print('\\nThe correlation matrix obtained from exact ground state\\n',correlations.round(2))\n",
    "\n",
    "shadow_correlations, shadow = shadow_corr(num_snaps,H)\n",
    "print('\\nThe correlation matrix directly predicted by classical shadows\\n', shadow_correlations.round(2))\n",
    "\n",
    "g_shadow, g_values = groundstate_shadow(num_snaps,H)\n",
    "shadow_predicted_energy = obs_prediction(H,g_shadow,5)\n",
    "reconstructed = reconstructed_state(g_shadow)\n",
    "shadow_energy = np.real(np.trace(np.matmul(H,reconstructed)))\n",
    "print('\\nShadow Prediction of GSE:',shadow_predicted_energy)\n",
    "print('\\nShadow Computation of GSE:',shadow_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5c9cfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17495b3a460>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Visual Plots for Comparison'''\n",
    "f, axarr = plt.subplots(1,3)\n",
    "\n",
    "axarr[0].set_title('Exact')\n",
    "axarr[0].imshow(correlations, cmap=plt.get_cmap(\"RdBu\"), vmin = -1,vmax = 1)\n",
    "\n",
    "axarr[1].set_title('Classical Shadow')\n",
    "axarr[1].imshow(shadow_correlations, cmap=plt.get_cmap(\"RdBu\"), vmin = -1,vmax = 1)\n",
    "\n",
    "axarr[2].set_title('Difference')\n",
    "axarr[2].imshow(correlations-shadow_correlations, cmap=plt.get_cmap(\"RdBu\"), vmin = -1,vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f3c5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(num_data, model_shape, num_snaps):\n",
    "    \n",
    "    params, shadows, states, measurements = [], [], [], []\n",
    "    \n",
    "    for i in range(num_data):\n",
    "        J, terms = random_couplings(model_shape[0], model_shape[1])\n",
    "        H = Heisenberg_Model(J)\n",
    "        gshadow, val = groundstate_shadow(num_snaps,H)\n",
    "        state = reconstructed_state(gshadow)\n",
    "        shadows.append(gshadow)\n",
    "        measurements.append(val)\n",
    "        params.append(terms)\n",
    "        states.append(state)\n",
    "        \n",
    "    return np.array(params), np.array(shadows), np.array(states), np.array(measurements)\n",
    "\n",
    "params, shadows, states, measurements  = generate_dataset(num_data=100, model_shape=(2,2), num_snaps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a250ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encoding once in log space\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        return x\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    attention_weights = nn.functional.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        attention_weights = dropout(attention_weights)\n",
    "\n",
    "    context = torch.matmul(attention_weights, value)\n",
    "    return context, attention_weights\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, d_model, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.linear_q = nn.Linear(d_model, d_model)\n",
    "        self.linear_k = nn.Linear(d_model, d_model)\n",
    "        self.linear_v = nn.Linear(d_model, d_model)\n",
    "        self.linear_o = nn.Linear(d_model, d_model)\n",
    "        self.attn = None\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "\n",
    "        n_batches = query.size(0)\n",
    "        query, key, value = [\n",
    "            lin(x).view(n_batches, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        x = x.transpose(1, 2).contiguous().view(n_batches, -1, self.n_heads * self.d_k)\n",
    "\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)\n",
    "    \n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True, unbiased=False)\n",
    "        return ((x - mean) / (std + self.eps)) * self.gamma + self.beta\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    \n",
    "import torch.nn as nn\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn: MultiHeadAttention, feed_forward: PositionWiseFeedForward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer1 = SublayerConnection(size, dropout)\n",
    "        self.sublayer2 = SublayerConnection(size, dropout)\n",
    "        self.sublayer3 = SublayerConnection(size, dropout)\n",
    "\n",
    "    def forward(self, x, tgt_mask):\n",
    "        x = self.sublayer1(x, lambda x: self.self_attn(\n",
    "            query=x, key=x, value=x, mask=tgt_mask\n",
    "        ))\n",
    "        x = self.sublayer2(x, lambda x: self.self_attn(\n",
    "            query=x, key=x, value=x, mask=tgt_mask\n",
    "        ))\n",
    "        return self.sublayer3(x, self.feed_forward)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer: DecoderLayer, n_layers: int):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(layer)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, tgt_mask=mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50dab491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TgtBatch:\n",
    "    def __init__(self, tgt, pad):\n",
    "        self.tgt = tgt[:, :-1]\n",
    "        self.tgt_y = tgt[:, 1:]\n",
    "        self.tgt_mask = make_std_mask(self.tgt, pad)\n",
    "        self.ntokens = (self.tgt_y != pad).data.sum()\n",
    "        \n",
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
    "    return mask == 0\n",
    "\n",
    "\n",
    "def make_std_mask(tgt, pad):\n",
    "    tgt_mask = (tgt != pad).unsqueeze(-2) \n",
    "    tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n",
    "    return tgt_mask\n",
    "\n",
    "\n",
    "def batch_iterator(data, graphs_list, iterations, batch_size, shuffle=True):\n",
    "    for step in range(1, iterations + 1):\n",
    "        indices = rng.choice(len(data), batch_size, replace=True)\n",
    "        tgt_batch = TgtBatch(data[indices], pad=-1)\n",
    "        graphs_batch = GraphBatch.from_data_list(data_list=[graphs_list[i] for i in indices])\n",
    "        yield tgt_batch, graphs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ba744fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, num_qubits, input_dim, gcn_dim, transformer_dim, num_layers):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        channel = [input_dim]\n",
    "        channel = channel + [2 ** (num_layers - 1 - i) * gcn_dim for i in range(num_layers - 1)]\n",
    "        channel = channel + [gcn_dim]\n",
    "        \n",
    "        self.transformer = transformer_dim\n",
    "        self.channels = gcn_dim\n",
    "        self.nodes = num_qubits\n",
    "        \n",
    "        self.gcn = []\n",
    "        for i in range(len(channel)-1):\n",
    "            self.gcn.append(GCNConv(channel[i],channel[i+1]))\n",
    "        \n",
    "        self.linear = nn.Linear(num_qubits*gcn_dim, transformer_dim)\n",
    "        self.layers = nn.Sequential(*self.gcn, self.linear)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, index, weight = data.x, data.edge_index, data.edge_weight\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x, index, weight).relu()\n",
    "\n",
    "        embed = x.view(-1, self.channels * self.nodes)\n",
    "        proj = self.layers[-1](embed)\n",
    "        proj = proj.view(data.num_graphs, -1, self.transformer)\n",
    "        return proj\n",
    "\n",
    "num_qubits = len(coupling)\n",
    "input_dim = len(measurements[0][0])\n",
    "gcn_dim = 16\n",
    "transformer_dim = 128\n",
    "num_layers = 3\n",
    "encoder = GCNEncoder(num_qubits, input_dim, gcn_dim, transformer_dim, num_layers)\n",
    "\n",
    "\n",
    "class GraphTransformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, embed, generator, num_outcomes, dim_model, pad_token, start_token, end_token, token_shift):\n",
    "        super(GraphTransformer, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.embed = embed\n",
    "        self.generator = generator\n",
    "        self.num_outcomes = num_outcomes\n",
    "        self.dim_model = dim_model\n",
    "\n",
    "        self.pad_token = pad_token\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.token_shift = token_shift\n",
    "\n",
    "    def forward(self, tgt, tgt_mask, coupling_graph):\n",
    "        embed = self.embed(tgt)\n",
    "        graph_embed = self.encoder(coupling_graph)\n",
    "        graph_embed = graph_embed[:, :embed.shape[1], :]\n",
    "        embed = embed + graph_embed\n",
    "\n",
    "        return graph_embed, self.decoder(embed, tgt_mask)\n",
    "\n",
    "    def sample_batch(self, batch_size, coupling_graph, qubits):\n",
    "        num_valid_samples = 0\n",
    "        valid_samples = None\n",
    "\n",
    "        num_restarts = 0\n",
    "\n",
    "        while num_valid_samples < batch_size:\n",
    "            tgt = torch.ones(batch_size - num_valid_samples, 1).type(\n",
    "                LongTensor) * self.start_token\n",
    "\n",
    "            for i in range(qubits):\n",
    "                mask = make_std_mask(tgt, pad=self.pad_token)\n",
    "\n",
    "                _, out = self.forward(tgt, mask, coupling_graph)\n",
    "                log_probs = self.generator(out[:, -1])\n",
    "                probs = torch.exp(log_probs).detach()\n",
    "                probs = probs / probs.sum(axis=-1).reshape(\n",
    "                    batch_size - num_valid_samples, 1)\n",
    "\n",
    "                next_outcomes = torch.multinomial(probs, 1, replacement=True)\n",
    "\n",
    "                tgt = torch.cat([tgt, next_outcomes], dim=1)\n",
    "            tgt = tgt.cpu().numpy()\n",
    "            tgt = tgt[:, 1:] - self.token_shift\n",
    "            tgt = tgt[np.all(tgt >= 0, axis=1), :]\n",
    "\n",
    "            if valid_samples is None:\n",
    "                valid_samples = tgt\n",
    "            else:\n",
    "                valid_samples = np.concatenate([valid_samples, tgt], axis=0)\n",
    "\n",
    "            num_valid_samples = valid_samples.shape[0]\n",
    "\n",
    "            num_restarts += 1\n",
    "            if num_restarts > 10:\n",
    "                print(\n",
    "                    f'sampling timed out: got {num_valid_samples} instead of {batch_size}')\n",
    "                break\n",
    "\n",
    "        return valid_samples\n",
    "\n",
    "    def sample(self, samples, coupling_graph, qubits, batch_size=1000,\n",
    "               print_progress=True) -> np.ndarray:\n",
    "        batch_sizes = [batch_size] * int(samples // batch_size)\n",
    "        batch_sizes = batch_sizes + (\n",
    "            [] if samples % batch_size == 0 else [samples % batch_size])\n",
    "\n",
    "        if print_progress:\n",
    "            pbar = tqdm(batch_sizes,\n",
    "                        postfix=f'generating {samples} samples from model...')\n",
    "        else:\n",
    "            pbar = batch_sizes\n",
    "\n",
    "        batch_samples = [self.sample_batch(bs, coupling_graph, qubits) for bs in pbar]\n",
    "        samples = np.concatenate(batch_samples, axis=0)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b595005",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4\n",
    "num_layers = 4\n",
    "dim_model = 128\n",
    "dim_ff = 4*128\n",
    "num_outcomes = 6\n",
    "dropout = 0.0\n",
    "pad_token = -1\n",
    "start_token = 0\n",
    "end_token = -1\n",
    "token_shift = 1\n",
    "\n",
    "attention = MultiHeadAttention(num_heads, dim_model, dropout)\n",
    "feedforward = PositionWiseFeedForward(dim_model, dim_ff, dropout)\n",
    "position = PositionalEncoding(dim_model, dropout)\n",
    "size = num_outcomes + token_shift\n",
    "\n",
    "generator = Generator(dim_model, size)\n",
    "decoder = Decoder(DecoderLayer(dim_model, deepcopy(attention), deepcopy(feedforward), dropout), n_layers = num_layers)\n",
    "embed = nn.Sequential(Embedding(dim_model, size), deepcopy(position))\n",
    "\n",
    "model = GraphTransformer(encoder, decoder, embed, generator, num_outcomes, dim_model, pad_token, start_token, end_token, token_shift)\n",
    "\n",
    "for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2865bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDLoss(nn.Module):\n",
    "    def __init__(self, padding):\n",
    "        super(KLDLoss, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction='sum')\n",
    "        self.padding = padding\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        onehot = torch.zeros_like(x)\n",
    "        onehot.scatter_(1, target.unsqueeze(1), 1.0)\n",
    "        if self.padding >= 0:\n",
    "            onehot[:, self.padding] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding)\n",
    "        if mask.dim() > 0:\n",
    "            onehot.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        loss = self.criterion(x, target_onehot)\n",
    "        return loss\n",
    "\n",
    "criterion = KLDLoss(padding=-1)\n",
    "steps = 200\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=steps, eta_min=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "886be774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "train_samples = 1000\n",
    "wires = 4\n",
    "J, coeffs = random_couplings(2,2)\n",
    "H = Heisenberg_Model(J)\n",
    "gstate, gvalue = ground_state(H)\n",
    "\n",
    "shad, val = groundstate_shadow(1000,H)\n",
    "val = val + 1 \n",
    "val = np.concatenate([0 * np.ones(shape=(1000, 1)), val], axis=1)\n",
    "val = val.astype(int)\n",
    "val = torch.from_numpy(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f95460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = [graph_data(J) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367e7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
